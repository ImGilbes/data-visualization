{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5787b4e",
   "metadata": {},
   "source": [
    "### PCA:\n",
    "* Main bullet point\n",
    "    * Sub bullet point\n",
    "        * subsub\n",
    "Dimensionality reduction technique that aims at minimizing the information loss, where the information is given by the variance of the data on a certain direction.\n",
    "\n",
    "PCA creates a new set of variables |x_new| < |x_old| that are uncorrelated and encode the data along the first n principal components. Principal components represent the directions along which the data has the maximal variance.  As an example, the first component is the direction with most possible variance in the dataset, the second component the direction with the second highest variance, etc. The first n components form new axes on which the data in the original space can be projected.\n",
    "\n",
    "The procedure is the following:\n",
    "* Data needs to be standardized before applying PCA ( a x f )\n",
    "* Step 1: compute the covariance matrix ( f x f ) - you can use SVD or correlation matrix too\n",
    "* Step 2: computer eigenvectors of Cov(data). The eigenvectors represent the principal components and their eigenvalues are the variance of each component ( f x f )\n",
    "* Step 3: sort (descensind order) the eigenvectors by eigenvalue to obtain the first n principal components ( f x f )\n",
    "* Step 4: discard the last index > n principal components (eigenvectors) ( f x n )\n",
    "* Step 5: the new dataset is simply given by the dot product of the original standardized dataset with the n first principal components ( f x n )T ( a x f)T\n",
    "\n",
    "PCA is linear dimensionality reduction method because the dataset in the new feature space is the result of linear combinations of the original dataset (dot product)\n",
    "\n",
    "* Pros:\n",
    "    * PCA can be used for reducing noise since it removes those directions with little impact on the information of the data. \n",
    "    * It can be used as a pre processing technique (other than for removing noise, you can use it to simplify the dataset) - just remove a small number of dimensions like 10 > 8, or 100 > 90\n",
    "    * Allows to plot high-dimensiionality datasets (see cons)\n",
    "        \n",
    "* Cons:\n",
    "    * Does not keep information on the structure of the data, both locally and globally\n",
    "    * PCA is overshadowed by many other algorithms when it comes to data exploration tasks. It is hard to visualize data and its global structure - graph-based algorithms are better in that regard.\n",
    "    * Can only preserve linear relationships between variables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c978d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071baba",
   "metadata": {},
   "source": [
    "### MDS:\n",
    "\n",
    "MDS is a family of techniques that can be use for dimensionality reduction as well as a number of other tasks in which is it required to discover the hidden structure of data.\n",
    "\n",
    "The goal of MDS algorithms is to find a representation of data in lower-dimensional spaces that preserves similarities ( = distance) between data points.\n",
    "\n",
    "MDS algorithms are classified in two main categories: metric and non-metric. The first type assumes that the distance between data points in the lower-dimensional space is a function of the similarity in the higher-dimensional space. Non-metric MDS relaxes this definition, and assumes that pairwise similarities keep their order once scaled to lower-dim. This means that if d(a,b) > d(b,c) in the original feature space, that has to be true also in the target feature space.\n",
    "\n",
    "In the classic algorithm (there are many modern/updated variations) the precedure is the following:\n",
    "* Construct a pairwise similarity matrix (can use euclidean distance)\n",
    "* Center the similarity matrix\n",
    "\n",
    "\n",
    "* Pros:\n",
    "    * Because it preserves similarities, MDS is great for data such as correlations, ratings (with the same scale) , or pairwise distances - in general data that embed on their own the notion of similarity.\n",
    "    * In general it preserves pairwise relationships (it was created for that)\n",
    "    * It can encode non-linear relationships between variables (PCA cannot, it's a linear technique)\n",
    "* Cons:\n",
    "    * It's of little use for visualizing densely populated datasets, like MNIST.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a2ea5",
   "metadata": {},
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2228ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16f5dc58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe494567",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c089b980",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3579c734",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cc6e080",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852968d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e80922da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fc697f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcd61c01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d458439e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b82e539",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
